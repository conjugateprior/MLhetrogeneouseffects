data_uganda <- data_uganda %>%
mutate(worry_job = replace_na(worry_job, 1))
#satisfaction income
data_uganda$satisf_income_na <- ifelse(is.na(data_uganda$satisf_income), 1, 0)
data_uganda <- data_uganda %>%
mutate(satisf_income = replace_na(satisf_income, 1))
#self employed
data_uganda$selfempl_na <- ifelse(is.na(data_uganda$selfempl), 1, 0)
data_uganda <- data_uganda %>%
mutate(selfempl = replace_na(selfempl, 1))
#hours worked year employed
data_uganda$hsworked_year_empl_na <- ifelse(is.na(data_uganda$hsworked_year_empl), 1, 0)
data_uganda <- data_uganda %>%
mutate(hsworked_year_empl = replace_na(hsworked_year_empl, 1))
#hours worked year self employed
data_uganda$hsworked_year_self_na <- ifelse(is.na(data_uganda$hsworked_year_self), 1, 0)
data_uganda <- data_uganda %>%
mutate(hsworked_year_self = replace_na(hsworked_year_self, 1))
#income
data_uganda$income_na <- ifelse(is.na(data_uganda$income), 1, 0)
data_uganda <- data_uganda %>%
mutate(income = replace_na(income, 1))
#index_empowerment
data_uganda$index_empowerment_na <- ifelse(is.na(data_uganda$index_empowerment), 1, 0)
data_uganda <- data_uganda %>%
mutate(index_empowerment = replace_na(index_empowerment, 1))
#children
data_uganda$children_na <- ifelse(is.na(data_uganda$children), 1, 0)
data_uganda <- data_uganda %>%
mutate(children = replace_na(children, 1))
#life_skills
data_uganda$life_skills_na <- ifelse(is.na(data_uganda$life_skills), 1, 0)
data_uganda <- data_uganda %>%
mutate(life_skills = replace_na(life_skills, 1))
#livelihood
data_uganda$livelihood_na <- ifelse(is.na(data_uganda$livelihood), 1, 0)
data_uganda <- data_uganda %>%
mutate(livelihood = replace_na(livelihood, 1))
#rural
data_uganda$rural_na <- ifelse(is.na(data_uganda$rural), 1, 0)
data_uganda <- data_uganda %>%
mutate(rural = replace_na(rural, 1))
#age
data_uganda$age_na <- ifelse(is.na(data_uganda$age), 1, 0)
data_uganda <- data_uganda %>%
mutate(age = replace_na(age, 1))
## Make sure the data has no missing values (outcome and treatment to run causal forests!!!)
#data_uganda_is.na <- data_uganda[!is.na(data_uganda$foll_index_income_gen_act), ]
data_uganda_na <- as_tibble(data_uganda_is.na)
# Evaluate the rmse on both training and test data and print them
#The root mean squared error (RMSE) is the average prediction error (square root of mean squared error).
#https://bookdown.org/mpfoley1973/data-sci/model-validation.html
rmse_train <- rmse(cf.basic$predictions, data_uganda_train$foll_index_income_gen_act)
## Make sure the data has no missing values (outcome and treatment to run causal forests!!!)
#data_uganda_is.na <- data_uganda[!is.na(data_uganda$foll_index_income_gen_act), ]
#data_uganda_na <- as_tibble(data_uganda_is.na)
data_uganda <- data_uganda %>%
filter(complete.cases(foll_index_aspiration,
foll_index_empowerment,
foll_index_income_gen_act,
index_empowerment,
children,
branchno,
age,
rural,
income,
enroll_school,
study_hours,
vill_id))
save(data_uganda,file="data_uganda.Rda")
## Datacamp method (ratio 75:25); most of causal forest use this ratio but haven't found true argument to chose this ratio.
# Get number of rows
N <- nrow(data_uganda)
# Calculate how many rows 75% of N should be and print it; we use round to get an integer
target <- round(N * 0.75)
# Create the vector of N uniform random variables: rv
rv <- runif(N)
# Use rv to create the training set: ud_train (75% of data) and ud_test (25% of data)
data_uganda_train <- data_uganda[rv < 0.75, ]
data_uganda_test <- data_uganda[rv >= 0.75, ]
# Use nrow() to examine ud_train and ud_test
nrow(data_uganda_train)
nrow(data_uganda_test)
## I think it is large enough the data set --> we don't need cross validation to split the data!
# Other method (ratio 70:30)
set.seed(400) # To always run same answer; or just put seed
train <- sample(nrow(data_uganda_na), 0.7*nrow(data_uganda_na), replace = FALSE)
## Datacamp method (ratio 75:25); most of causal forest use this ratio but haven't found true argument to chose this ratio.
# Get number of rows
N <- nrow(data_uganda)
# Calculate how many rows 75% of N should be and print it; we use round to get an integer
target <- round(N * 0.75)
# Create the vector of N uniform random variables: rv
rv <- runif(N)
# Use rv to create the training set: ud_train (75% of data) and ud_test (25% of data)
data_uganda_train <- data_uganda[rv < 0.75, ]
data_uganda_test <- data_uganda[rv >= 0.75, ]
# Use nrow() to examine ud_train and ud_test
nrow(data_uganda_train)
nrow(data_uganda_test)
## I think it is large enough the data set --> we don't need cross validation to split the data!
# Other method (ratio 70:30)
set.seed(400) # To always run same answer; or just put seed
train <- sample(nrow(data_uganda), 0.7*nrow(data_uganda), replace = FALSE)
data_uganda_train_v2 <- data_uganda_na[train,] #  Train is like the data we would collect in a randomized experiment
data_uganda_train_v2 <- data_uganda[train,] #  Train is like the data we would collect in a randomized experiment
data_uganda_valid_v2 <- data_uganda[-train,] # Test would be the future cases which we are trying to predict
summary(data_uganda_train_v2)
summary(data_uganda_train_v2)
nrow(data_uganda_train_v2)
nrow(data_uganda_train_v2)
summary(data_uganda_valid_v2)
library(grf)
# Random seed to reproduce results
set.seed
## INCOME GENERATING ACTIVITY - IGA
# Create outcome and inputs for the Causal Forests (important all numeric; including dummy code the factor variables)
Y_outcome <- as.matrix(data_uganda_train$foll_index_income_gen_act) # Vector outcome of interest
#attach outcome to train data
Y_aspiration <- as.matrix(data_uganda_train$foll_index_aspiration)
Y_empower <- as.matrix(data_uganda_train$foll_index_empowerment)
X_vars <- model.matrix(lm (Y_outcome ~ children + children_na +
branchno + branchno_na +
age + age_na +
rural + rural_na +
income + income_na +
enroll_school + enroll_school_na +
study_hours+ study_hours_na +
index_empowerment + index_empowerment_na +
enroll_school*study_hours +
enroll_school_na*study_hours_na +
children*age +
children_na*age_na,
data = data_uganda_train)) # X is a matrix of the covariates which we are using to predict heterogeneity in treatment effect
X_baseline <- model.matrix(lm(Y_outcome ~ children + children_na +
branchno + branchno_na +
age + age_na +
rural + rural_na +
income + income_na +
enroll_school + enroll_school_na +
study_hours+ study_hours_na +
index_empowerment + index_empowerment_na +
att_earn_moneyfam + att_earn_moneyfam_na +
z_Entrep_total + z_Entrep_total_na +
z_Expenditure_totDF + z_Expenditure_totDF_na +
value_assets + value_assets_na +
loan_brac + loan_brac_na +
ablework_married + ablework_married_na +
M_marrywhen + M_marrywhen_na +
who_decidehusband + who_decidehusband_na +
work_married + work_married_na +
want_respect + want_respect_na +
worry_job + worry_job_na +
satisf_income + satisf_income_na +
selfempl + selfempl_na +
hsworked_year_empl + hsworked_year_empl_na +
hsworked_year_self + hsworked_year_self_na +
life_skills + life_skills_na +
livelihood + livelihood_na +
enroll_school*study_hours +
enroll_school_na*study_hours_na +
children*age +
children_na*age_na,
data = data_uganda_train))
#cluster
C_vars <- data_uganda_train$vill_id
# Treatment assignment
W_treatment <- as.matrix(data_uganda_train$treatment)
Y.forest = regression_forest(X_baseline, Y_outcome, clusters = C_vars)
Y.hat = predict(Y.forest)$predictions
W.forest = regression_forest(X_baseline,
W_treatment,
clusters = C_vars)
W.hat = predict(W.forest)$predictions
cf.raw = causal_forest (X_baseline,
Y_outcome,
W_treatment,
Y.hat = Y.hat,
W.hat = W.hat,
clusters = C_vars)
#test set
preds_cf <- predict(
object = cf.raw,
newdata = model.matrix(~ children + children_na +
branchno + branchno_na +
age + age_na +
rural + rural_na +
income + income_na +
enroll_school + enroll_school_na +
study_hours+ study_hours_na +
index_empowerment + index_empowerment_na +
att_earn_moneyfam + att_earn_moneyfam_na +
z_Entrep_total + z_Entrep_total_na +
z_Expenditure_totDF + z_Expenditure_totDF_na +
value_assets + value_assets_na +
loan_brac + loan_brac_na +
ablework_married + ablework_married_na +
M_marrywhen + M_marrywhen_na +
who_decidehusband + who_decidehusband_na +
work_married + work_married_na +
want_respect + want_respect_na +
worry_job + worry_job_na +
satisf_income + satisf_income_na +
selfempl + selfempl_na +
hsworked_year_empl + hsworked_year_empl_na +
hsworked_year_self + hsworked_year_self_na +
life_skills + life_skills_na +
livelihood + livelihood_na +
enroll_school*study_hours +
enroll_school_na*study_hours_na +
children*age +
children_na*age_na,
data= data_uganda_test),
estimate.variance = TRUE
)
#average treatment effect for the raw model
ATE = average_treatment_effect(cf.raw)
paste("95% CI for the ATE:", round(ATE[1], 3),
"+/-", round(qnorm(0.975) * ATE[2], 3))
#accuracy check for raw model
accuracy <- postResample(pred = preds_cf$predictions,
obs = data_uganda_test$foll_index_income_gen_act)
accuracy
#after training a raw model with all baseline variables, it is recommended to train additional model only with important variable
##check for variable importance
varimp = variable_importance(cf.raw)
selected.idx = which(varimp > mean(varimp)) #select only important variables and train another causal forest using only important variables
cf = causal_forest(X_baseline[,selected.idx],
Y_outcome, W_treatment,
Y.hat = Y.hat,
W.hat = W.hat,
num.trees = 3000,
clusters = C_vars,
tune.parameters = "all")
tau.hat = predict(cf)$predictions
#average treatment effect for the model with important variables
ATE = average_treatment_effect(cf)
paste("95% CI for the ATE:", round(ATE[1], 3),
"+/-", round(qnorm(0.975) * ATE[2], 3))
#
# Omnibus tests for heterogeneity
#
# Run best linear predictor analysis
test_calibration(cf)
# Compare villages with high and low estimated CATEs
high_effect = tau.hat > median(tau.hat)
ate.high = average_treatment_effect(cf, subset = high_effect)
ate.low = average_treatment_effect(cf, subset = !high_effect)
paste("95% CI for difference in ATE:",
round(ate.high[1] - ate.low[1], 3), "+/-",
round(qnorm(0.975) * sqrt(ate.high[2]^2 + ate.low[2]^2), 3))
#####predict test set on only important variables
imp.variables.test <- data_uganda_test %>% select() #need to check how to select only important variables to check run the new model cf
imp.variables.test
#train causal forest
cf.basic <- causal_forest(X = X_vars,
Y = Y_outcome,
W = W_treatment,
Y.hat = Y.hat,
W.hat = W.hat,
num.trees = 3000, #more trees result in better confident intervals
clusters = C_vars,
orthog.boosting = TRUE,
tune.parameters = "all")# paper clusters
# but see again!!! Athey and Wager 2019; orthogonalization
##check for variable importance
varimp.basic = variable_importance(cf.basic)
selected.idx.basic = which(varimp.basic > mean(varimp.basic)) #select only important variables and train another causal forest using only important variables
selected.idx.basic
## Predict the test data
# Tell grf to include variance estimates, and then I assign the predictions (the estimated treatment effects) to the test data frame so that we can use these in subsequent analyses
preds_IGA <- predict(
object = cf.basic,
newdata = model.matrix(~ children + children_na +
branchno + branchno_na +
age + age_na +
rural + rural_na +
income + income_na +
enroll_school + enroll_school_na +
study_hours+ study_hours_na +
index_empowerment + index_empowerment_na +
enroll_school*study_hours +
enroll_school_na*study_hours_na +
children*age +
children_na*age_na,
data= data_uganda_test),
estimate.variance = TRUE
)
# but see again!!! Athey and Wager 2019; orthogonalization
##check for variable importance
varimp.basic = variable_importance(cf.basic)
View(varimp.basic)
# Estimate the conditional average treatment effect on the full sample (CATE).
average_treatment_effect(cf.raw, target.sample = "all")
# Check whether causal forest predictions are well calibrated.
test_calibration(cf.forest)
#after training a raw model with all baseline variables, it is recommended to train additional model only with important variable
##check for variable importance
varimp = variable_importance(cf.raw)
selected.idx = which(varimp > mean(varimp)) #select only important variables and train another causal forest using only important variables
cf = causal_forest(X_baseline[,selected.idx],
Y_outcome, W_treatment,
Y.hat = Y.hat,
W.hat = W.hat,
num.trees = 3000,
clusters = C_vars,
tune.parameters = "all")
cf = causal_forest(X_baseline[,selected.idx],
Y_outcome, W_treatment,
Y.hat = Y.hat,
W.hat = W.hat,
num.trees = 3000,
clusters = C_vars,
tune.parameters = "all")
tau.hat = predict(cf)$predictions
tau.hat = predict(cf)$predictions
# Check whether causal forest predictions are well calibrated.
test_calibration(cf.forest)
# Check whether causal forest predictions are well calibrated.
test_calibration(cf)
?test_calibration
test_calibration(cf)
#Finds the optimal ridge penalty for local linear causal prediction.
#A list of lambdas tried, corresponding errors, and optimal ridge penalty lambda.
tune_ll_causal_forest(
cf,
linear.correction.variables = NULL,
ll.weight.penalty = FALSE,
num.threads = NULL,
lambda.path = NULL
)
?regression_forest
?test_calibration
tau.hat = predict(cf)$predictions
hist(tau.hat$predictions)
#Load libraries
library(haven)
library(caret)
library(tidyverse) # remember includes dplyr
library(expss)
library(summarytools)
library(mice)
hist(tau.hat$prediction)
tau.hat = predict(cf)
hist(tau.hat$prediction)
hist(tau.hat$predictions)
#test set
X.test <- model.matrix(lm(Y_outcome ~ children + children_na +
branchno + branchno_na +
age + age_na +
rural + rural_na +
income + income_na +
enroll_school + enroll_school_na +
study_hours+ study_hours_na +
index_empowerment + index_empowerment_na +
att_earn_moneyfam + att_earn_moneyfam_na +
z_Entrep_total + z_Entrep_total_na +
z_Expenditure_totDF + z_Expenditure_totDF_na +
value_assets + value_assets_na +
loan_brac + loan_brac_na +
ablework_married + ablework_married_na +
M_marrywhen + M_marrywhen_na +
who_decidehusband + who_decidehusband_na +
work_married + work_married_na +
want_respect + want_respect_na +
worry_job + worry_job_na +
satisf_income + satisf_income_na +
selfempl + selfempl_na +
hsworked_year_empl + hsworked_year_empl_na +
hsworked_year_self + hsworked_year_self_na +
life_skills + life_skills_na +
livelihood + livelihood_na +
enroll_school*study_hours +
enroll_school_na*study_hours_na +
children*age +
children_na*age_na,
data = data_uganda_test))
#test set
X.test <- model.matrix(lm(~ children + children_na +
branchno + branchno_na +
age + age_na +
rural + rural_na +
income + income_na +
enroll_school + enroll_school_na +
study_hours+ study_hours_na +
index_empowerment + index_empowerment_na +
att_earn_moneyfam + att_earn_moneyfam_na +
z_Entrep_total + z_Entrep_total_na +
z_Expenditure_totDF + z_Expenditure_totDF_na +
value_assets + value_assets_na +
loan_brac + loan_brac_na +
ablework_married + ablework_married_na +
M_marrywhen + M_marrywhen_na +
who_decidehusband + who_decidehusband_na +
work_married + work_married_na +
want_respect + want_respect_na +
worry_job + worry_job_na +
satisf_income + satisf_income_na +
selfempl + selfempl_na +
hsworked_year_empl + hsworked_year_empl_na +
hsworked_year_self + hsworked_year_self_na +
life_skills + life_skills_na +
livelihood + livelihood_na +
enroll_school*study_hours +
enroll_school_na*study_hours_na +
children*age +
children_na*age_na,
data = data_uganda_test))
#test set
X.test <- model.matrix(lm(foll_index_income_gen_act ~ children + children_na +
branchno + branchno_na +
age + age_na +
rural + rural_na +
income + income_na +
enroll_school + enroll_school_na +
study_hours+ study_hours_na +
index_empowerment + index_empowerment_na +
att_earn_moneyfam + att_earn_moneyfam_na +
z_Entrep_total + z_Entrep_total_na +
z_Expenditure_totDF + z_Expenditure_totDF_na +
value_assets + value_assets_na +
loan_brac + loan_brac_na +
ablework_married + ablework_married_na +
M_marrywhen + M_marrywhen_na +
who_decidehusband + who_decidehusband_na +
work_married + work_married_na +
want_respect + want_respect_na +
worry_job + worry_job_na +
satisf_income + satisf_income_na +
selfempl + selfempl_na +
hsworked_year_empl + hsworked_year_empl_na +
hsworked_year_self + hsworked_year_self_na +
life_skills + life_skills_na +
livelihood + livelihood_na +
enroll_school*study_hours +
enroll_school_na*study_hours_na +
children*age +
children_na*age_na,
data = data_uganda_test))
pred.cf <- predict(cf.raw, X.test, data=data_uganda_test)
pred.cf <- predict(cf.raw, X.test, data=data_uganda_test, estimate.variance = TRUE)
plot(X.test[, 1], tau.hat$predictions, ylim = range(tau.hat$predictions, 0, 2), xlab = "x", ylab = "tau", type = "l")
plot(X.test[, 1], pred.cft$predictions, ylim = range(pred.cf$predictions, 0, 2), xlab = "x", ylab = "tau", type = "l")
plot(X.test[, 1], pred.cf$predictions, ylim = range(pred.cf$predictions, 0, 2), xlab = "x", ylab = "tau", type = "l")
lines(X.test[, 1], pmax(0, X.test[, 1]), col = 2, lty = 2)
# Estimate treatment effects for the test sample.
plot
plot(X.test[, 1], pred.cf$predictions, ylim = range(pred.cf$predictions, 0, 2), xlab = "x", ylab = "tau", type = "l")
lines(X.test[, 1], pmax(0, X.test[, 1]), col = 2, lty = 2)
plot(X.test[, 1], pred.cf$predictions, ylim = range(pred.cf$predictions, 0, 2), xlab = "x", ylab = "tau", type = "l")
plot
lines(X.test[, 1], pmax(0, X.test[, 1]), col = 2, lty = 2)
plot.new
lines(X.test[, 1], pmax(0, X.test[, 1]), col = 2, lty = 2)
# Estimate treatment effects for the test sample.
plot.new
plot(X.test[, 1], pred.cf$predictions, ylim = range(pred.cf$predictions, 0, 2), xlab = "x", ylab = "tau", type = "l")
lines(X.test[, 1], pmax(0, X.test[, 1]), col = 2, lty = 2)
plot(X.test[, 1], pred.cf$predictions, ylim = range(pred.cf$predictions, 0, 2), xlab = "x", ylab = "tau", type = "l")
lines(X.test[, 1], pmax(0, X.test[, 1]), col = 2, lty = 2)
View(pred.cf)
# Estimate treatment effects for the test sample.
####doesnt work yet
plot(X.test[, 1], pred.cf$predictions, ylim = range(pred.cf$predictions, 0, 2), xlab = "x", ylab = "tau", type = "l")
lines(X.test[, 1], pmax(0, X.test[, 1]), col = 2, lty = 2)
# Estimate the conditional average treatment effect on the full sample (CATE).
average_treatment_effect(cf.raw, target.sample = "all")
#average treatment effect for the raw model
ATE = average_treatment_effect(cf.raw)
paste("95% CI for the ATE:", round(ATE[1], 3),
"+/-", round(qnorm(0.975) * ATE[2], 3))
#accuracy check for raw model
accuracy <- postResample(pred = preds_cf$predictions,
obs = data_uganda_test$foll_index_income_gen_act)
accuracy
#after training a raw model with all baseline variables, it is recommended to train additional model only with important variable
##check for variable importance
varimp = variable_importance(cf.raw)
selected.idx = which(varimp > mean(varimp)) #select only important variables and train another causal forest using only important variables
cf = causal_forest(X_baseline[,selected.idx],
Y_outcome, W_treatment,
Y.hat = Y.hat,
W.hat = W.hat,
num.trees = 3000,
clusters = C_vars,
tune.parameters = "all")
tau.hat = predict(cf)
#plot frequency of predictions
hist(tau.hat$predictions)
#average treatment effect for the model with important variables
ATE = average_treatment_effect(cf)
paste("95% CI for the ATE:", round(ATE[1], 3),
"+/-", round(qnorm(0.975) * ATE[2], 3))
#
# Omnibus tests for heterogeneity
#
# Run best linear predictor analysis. Computes the best linear fit of the target estimand using the forest prediction (on held-out data) as well as the mean forest prediction as the sole two regressors. A coefficient of 1 for 'mean.forest.prediction' suggests that the mean forest prediction is correct, whereas a coefficient of 1 for 'differential.forest.prediction' additionally suggests that the forest has captured heterogeneity in the underlying signal. The p-value of the 'differential.forest.prediction' coefficient also acts as an omnibus test for the presence of heterogeneity: If the coefficient is significantly greater than 0, then we can reject the null of no heterogeneity.
test_calibration(cf)
#Finds the optimal ridge penalty for local linear causal prediction.
#A list of lambdas tried, corresponding errors, and optimal ridge penalty lambda.
tune_ll_causal_forest(cf,
linear.correction.variables = NULL,
ll.weight.penalty = FALSE,
num.threads = NULL,
lambda.path = NULL
)
# Compare villages with high and low estimated CATEs
high_effect = tau.hat > median(tau.hat)
# Compare villages with high and low estimated CATEs
high_effect = tau.hat > median(tau.hat)
plot(X.test[, 1], pred.cf$predictions, ylim = range(pred.cf$predictions, 0, 2), xlab = "x", ylab = "tau", type = "l")
lines(X.test[, 1], pmax(0, X.test[, 1]), col = 2, lty = 2)
